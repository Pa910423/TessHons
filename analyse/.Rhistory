names(firstTrial)
table(firstTrial$cond)
tb <- tb %>% mutate(cond = paste(stimType, spatial, ori, flipped, sep = '_'))
knitr::opts_chunk$set(echo = TRUE)
library(readr)
dataWithPath<- file.path("dataAnonymized","PSYC1anonymized")
#tb<- read_csv(  paste0(dataWithPath,".csv") )
tb<- readRDS( paste0(dataWithPath,".rda") )
#add practice column
practiceTrials = 5
tb<- tb %>% mutate(practice= (trialnum<practiceTrials))
tb <- tb %>% mutate(cond = paste(stimType, spatial, ori, flipped, sep = '_'))
#devtools::install_github("ropenscilabs/skimr")
#install.packages("tidyselect")  and from source to get 0.2.4 needed
library(skimr)
#skim(tb)
#get one trial per subject so can easily examine simple demographics like first language
firstTrial <- tb %>% filter(trialnum==0)
table(firstTrial$Yconsent,firstTrial$YshareData, dnn=c("consent","shareData"), useNA="ifany")
tc <- tb %>% filter(Yconsent == TRUE, YshareData==TRUE)
firstTrial <- tc %>% filter(trialnum==0)
table(firstTrial$firstReadLang)
table(tb$cond)
table(firstTrial$cond)
table(firstTrial$task)
table(firstTrial$numSimultaneousStim)
tb <- tb %>% mutate(cond = paste(numSimultaneousStim, stimType, spatial, ori, flipped, sep = '_'))
firstTrial <- tb %>% filter(trialnum==0)
table(firstTrial$cond)
knitr::opts_chunk$set(echo = TRUE)
three <- tc %>% filter(numSimultaneousStim==3)
knitr::opts_chunk$set(echo = TRUE)
three <- tc %>% filter(numSimultaneousStim==3)
library(dplyr)
three <- tc %>% filter(numSimultaneousStim==3)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
dataWithPath<- file.path("dataAnonymized","PSYC1anonymized")
#tb<- read_csv(  paste0(dataWithPath,".csv") )
tb<- readRDS( paste0(dataWithPath,".rda") )
#add practice column
practiceTrials = 5
tb<- tb %>% mutate(practice= (trialnum<practiceTrials))
tb <- tb %>% mutate(cond = paste(numSimultaneousStim, stimType, spatial, ori, flipped, sep = '_'))
#devtools::install_github("ropenscilabs/skimr")
#install.packages("tidyselect")  and from source to get 0.2.4 needed
library(skimr)
#skim(tb)
#get one trial per subject so can easily examine simple demographics like first language
firstTrial <- tb %>% filter(trialnum==0)
table(firstTrial$cond)
table(firstTrial$Yconsent,firstTrial$YshareData, dnn=c("consent","shareData"), useNA="ifany")
tc <- tb %>% filter(Yconsent == TRUE, YshareData==TRUE)
firstTrial <- tc %>% filter(trialnum==0)
table(firstTrial$firstReadLang)
table(firstTrial$"What is your age?")
table(firstTrial$"What is your biological sex?")
table(firstTrial$handedness)
library(dplyr)
three <- tc %>% filter(numSimultaneousStim==3)
View(three)
table(three$subject)
count(unique(three$subject)))
count(unique(three$subject))
length(unique(three$subject))
?suummarise_each
?summarise_each
tc %>% filter(practice==FALSE) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
table(tc$correct1)
table(tc$correct1,tc$correct0)
table(tc$correct0)
table(tc$correct2)
dd<- tc %>% filter(correct1==-999)
head(dd)
dd
dd<- tc %>% filter(correct1==-99)
dd
Vew(dd)
View(dd)
three %>% filter(practice==FALSE) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
three<- three  %>% filter(practice==FALSE)
three %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
t_horiz <- t.test(
x = three$correct0
, y = three$correct1
, paired = FALSE
)
t_horiz
oneTwo <- t.test(
x = three$correct0
, y = three$correct1
, paired = FALSE
)
oneTwo
twoThree <- t.test(
x = three$correct1
, y = three$correct2
, paired = FALSE
)
twoThree
names(three)
collapsed <- three %>% group_by(subject) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
head(collapsed)
collapsed
collapsed <- three %>% group_by(subject) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
oneTwo <- t.test(
x = collapsed$correct0
, y = collapsed$correct1
, paired = FALSE
)
oneTwo
twoThree <- t.test(
x = collapsed$correct1
, y = collapsed$correct2
, paired = FALSE
)
twoThree
collapsed %>% group_by(firstReadLang) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
names(collapseD)
names(collapsed)
three %>% group_by(subject,firstReadLang) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
three %>% group_by(subject %>% %>% summarise_all(funs(if_else(is.numeric(.), mean(.), first(.))))
three %>% group_by(subject) %>% summarise_all(funs(if_else(is.numeric(.), mean(.), first(.))))
three %>% group_by(subject) %>% summarise_all(funs(if_else(is.numeric(.), mean(.), NaN))) #first(.)
collapsed <- three %>% group_by(subject) %>% summarise_all(funs(if_else(is.numeric(.), mean(.), NaN))) #first(.)
collapsed %>% group_by(firstReadLang) %>% summarise_all(funs(if_else(is.numeric(.), mean(.), NaN))) #first(.)
collapsed %>% group_by(firstReadLang) %>%  summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
?summarise_at
#try keeping language only
cc <- collapsed %>% select(correct0,correct1,correct2,firstReadLang)
head(cc)
#try keeping language only
cc <- three %>% select(correct0,correct1,correct2,firstReadLang)
cc %>%    summarise_all(funs(if_else(is.numeric(.), mean(.), first(.)))) #first(.)
head(cc)
cc %>%    summarise_all(funs(if_else(is.numeric(.), mean(.), last(.)))) #first(.)
cc %>% summarise_if( is.numeric, mean)
cc %>%  group_by(firstReadLang) %>% summarise_all(funs(if_else(is.numeric(.), mean(.), last(.)))) #first(.)
cc %>%  group_by(firstReadLang) %>% summarise_if( is.numeric, mean)
table(three$firstReadLang)
table(three$firstReadLang,three$subject)
ccol <- three %>% group_by(subject,firstReadLang) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
ccol
collapsedSubjLang <- three %>% group_by(subject,firstReadLang) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
collapsedSubjLang %>% summarise_if( is.numeric, mean)
collapsedSubjLang
collapsedSubjLang %>% group_by(firstReadLang) %>% summarise_all(mean)
table(collapsedSubjLang$firstReadLang)
engSino <- t.test(
x = (collapsedSubjLang %>% filter(firstReadLang=="Chinese"))$correct0
, y = (collapsedSubjLang %>% filter(firstReadLang=="English"))$correct0
, paired = FALSE
)
engSino
engSino <- t.test(
x = (collapsedSubjLang %>% filter(firstReadLang=="Chinese"))$correct1
, y = (collapsedSubjLang %>% filter(firstReadLang=="English"))$correct1
, paired = FALSE
)
engSino
engSino <- t.test(
x = (collapsedSubjLang %>% filter(firstReadLang=="Chinese"))$correct2
, y = (collapsedSubjLang %>% filter(firstReadLang=="English"))$correct2
, paired = FALSE
)
engSino
collapsedSubjLang <- three %>% group_by(subject,firstReadLang) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
collapsedSubjLang %>% group_by(firstReadLang) %>% summarise_all(mean)  #works
mean(1,2,3)
mean(c(1,2,3))
bySubj <- three %>% group_by(subject) %>% mutate(avgCorr = mean(c("correct0","correct1","correct2"))
)
warnings()
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
dataWithPath<- file.path("dataAnonymized","PSYC1anonymized")
#tb<- read_csv(  paste0(dataWithPath,".csv") )
tb<- readRDS( paste0(dataWithPath,".rda") )
#add practice column
practiceTrials = 5
tb<- tb %>% mutate(practice= (trialnum<practiceTrials))
tb <- tb %>% mutate(cond = paste(numSimultaneousStim, stimType, spatial, ori, flipped, sep = '_'))
#devtools::install_github("ropenscilabs/skimr")
#install.packages("tidyselect")  and from source to get 0.2.4 needed
library(skimr)
#skim(tb)
#get one trial per subject so can easily examine simple demographics like first language
firstTrial <- tb %>% filter(trialnum==0)
table(firstTrial$cond)
table(firstTrial$Yconsent,firstTrial$YshareData, dnn=c("consent","shareData"), useNA="ifany")
tc <- tb %>% filter(Yconsent == TRUE, YshareData==TRUE)
firstTrial <- tc %>% filter(trialnum==0)
table(firstTrial$firstReadLang)
table(firstTrial$"What is your age?")
table(firstTrial$"What is your biological sex?")
table(firstTrial$handedness)
three <- tc %>% filter(numSimultaneousStim==3) %>% filter(practice==FALSE)
three %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
table(three$correct0,useNA="ifany")
three$correct0
bySubj <- three %>% group_by(subject) %>% mutate(avgCorr = mean(c("correct0","correct1","correct2")))
bySubj
three %>% group_by(subject) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE) %>%
summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
bySubj <- three %>% group_by(subject) %>% mutate(avgCorr = mean((correct0 + correct1 + correct2)/3)
c("correct0","correct1","correct2")))
bySubj <- three %>% group_by(subject) %>% mutate(avgCorr = mean((correct0 + correct1 + correct2)/3))
bySubj
three
three %>% un_group() %>% group_by(subject) %>% summarise_at(mean((correct0 + correct1 + correct2)/3))
three %>% group_by(subject) %>% summarise_at(mean((correct0 + correct1 + correct2)/3))
three %>% group_by(subject) %>% mutate(avgCorr = (correct0 + correct1 + correct2)/3))
three %>% group_by(subject) %>% mutate(avgCorr = (correct0 + correct1 + correct2)/3)
ti <- th %>% group_by(subject) %>% summarise_at(mean, avgCorr)
th<- three %>% group_by(subject) %>% mutate(avgCorr = (correct0 + correct1 + correct2)/3)
ti <- th %>% group_by(subject) %>% summarise_at(mean, avgCorr)
ti <- th %>% group_by(subject) %>% summarise_at(avgCorr, mean)
th<- three %>% group_by(subject) %>% mutate(avgCorr = (correct0 + correct1 + correct2)/3)
ti <- th %>% group_by(subject) %>% summarise_at(avgCorr, mean)
ti <- th %>% group_by(subject) %>% summarise_at("avgCorr", mean)
ti
losers <- ti %>% filter(avgCorr<.4)
losers
three %>% filter(subject==515)
View(three %>% filter(subject==515))
losers
losers <- unique(losers$subject)
losers
losers[1]
as.numeric(losers[1])
losers <- as.numeric( unique(losers$subject) )
three %>% filter(subject != as.numeric(losers[1]))
View(three %>% filter(subject==515))
1/15*1/14
#Count as a swap both answer0 = response2 and  answer2 = response0
#To include middle swaps, count as answer0 = response1, answer1 = response0, answer2=response1, answer1 = response2
swap <- three %>% mutate(swap02 = (answer0==response2), swap20 = (answer2==response0))
head(swap)
three %>% select(starts_with("ans"),starts_with("resp"),starts_with("corr"))
#Delete irrelevant columns
swap <- three %>% select(subject,starts_with("ans"),starts_with("resp"),starts_with("corr")))
#Delete irrelevant columns
swap <- three %>% select(subject,starts_with("ans"),starts_with("resp"),starts_with("corr"))
swap
swap <- swap %>% mutate(swap02 = (answer0==response2), swap20 = (answer2==response0))
swap
swap
swap <- swap %>% mutate(swap02 = (answer0==response2) & (response2!=answer2)) #matches other one and is not correct (which can happen with repetitions)
swap <- three %>% select(subject,starts_with("ans"),starts_with("resp"),starts_with("corr"))
swap <- swap %>% mutate(swap02 = (answer0==response2) & (response2!=answer2)) #matches other one and is not correct (which can happen with repetitions)
head(swap)
head(swap)
head(swap)
swap
swap %>% filter(swap02==TRUE)
swap <- three %>% select(subject,starts_with("ans"),starts_with("resp"),starts_with("corr"))
swap <- swap %>% mutate(swap02 = (answer0==response2) & (response2!=answer2)) #matches other one and is not correct (which can happen with repetitions)
swap <- swap %>% mutate(swap20 = (answer2==response0) & (response0!=answer0)) #matches other one and is not correct (which can happen with repetitions)
swap <- swap %>% mutate(swap01 = (answer0==response1) & (response1!=answer1)) #matches other one and is not correct (which can happen with repetitions)
swap <- swap %>% mutate(swap10 = (answer1==response0) & (response0!=answer0)) #matches other one and is not correct (which can happen with repetitions)
swap <- swap %>% mutate(swap12 = (answer1==response2) & (response2!=answer2)) #matches other one and is not correct (which can happen with repetitions)
swap <- swap %>% mutate(swap21 = (answer2==response1) & (response1!=answer1)) #matches other one and is not correct (which can happen with repetitions)
#Add up how many swaps.  answer   A B C
#                        response C B B   - one swap
swap %>% mutate(swaps = swap02+swap20+swap01+swap10+swap12+swap21)
#Add up how many swaps.  answer   A B C
#                        response C B B   - one swap
swap<-swap %>% mutate(swaps = swap02+swap20+swap01+swap10+swap12+swap21)
table(swap$swaps)
ti <- three %>% group_by(subject) %>% summarise_at("swap", mean)
swappers <- ti %>% filter(avgCorr<.4)
head(ti)
ti <- swap %>% group_by(subject) %>% summarise_at("swap", mean)
ti
names(swap)
ti <- swap %>% group_by(subject) %>% summarise_at("swaps", mean)
ti
ggplot(ti, aes(x=swaps)) + geom_hist()
ggplot2(ti, aes(x=swaps)) + geom_hist()
library(ggplot2)
ggplot(ti, aes(x=swaps)) + geom_hist()
ggplot(ti, aes(x=swaps)) + geom_histogram()
?count
swap %>% mutate(twoOrMore = swaps>=2)
swap<-swap %>% mutate(twoOrMore = swaps>=2)
ti <- swap %>% group_by(subject) %>% summarise_at(c("twoOrMore","swaps", mean)
)
ti <- swap %>% group_by(subject) %>% summarise_at(c("twoOrMore","swaps"), mean)
ti
ggplot(ti, aes(x=twoOrMore)) + geom_histogram()
swappers <- ti %>% filter(twoOrMore>.2)
print(swappers)
swappers
table(three$subject)
head(three)
three[,2]
class(three[,2]) <- "numeric"
as.numeric(three[,2])
three$subject[1]
str(three$subject[1])
a<-three$subject[1]
as.numeric(a)
Ss <- three$subject
as.numeric(Ss)
three$subject<- as.numeric(Ss)
three
swappers
swappers <-  unique(swappers$subject)
as.numeric(swappers)
nExclusions<- three %>% filter(  !(subject %in% swappers)   )
afterExclusions<- three %>% filter(  !(subject %in% swappers)   )
unique(afterExclusions$subject)
unique(afterExclusions$subject) ==1011
afterExclusions
collapsed <- afterExclusions %>% group_by(subject) %>% summarise_at(c("correct0", "correct1","correct2"), mean, na.rm = TRUE)
oneTwo <- t.test(
x = collapsed$correct0
, y = collapsed$correct1
, paired = FALSE
)
oneTwo
twoThree <- t.test(
x = collapsed$correct1
, y = collapsed$correct2
, paired = FALSE
)
twoThree
?save_csv
library(readr)
?save_csv
?write_csv
dataWithPath<- file.path("dataAnonymized","PSYC1anonymized")
library(readr)
write_tsv(collapsed, file.path(dataWithPath,"threeLetterTaskAfterExclusions.tsv")
)
getwd()
write_tsv(collapsed, file.path(dataWithPath,"threeLetterTaskAfterExclusions.tsv"))
write_tsv(collapsed, file.path(dataWithPath,"threeLetterTaskAfterExclusions.tsv"))
dataWithPath<- file.path("dataAnonymized")
library(readr)
write_tsv(collapsed, file.path(dataWithPath,"threeLetterTaskAfterExclusions.tsv"))
collapsed
write_tsv(afterExclusions, file.path(dataWithPath,"threeLetterTaskAfterExclusions.tsv"))
#currently without most columns, until learn how to preserve text columns etc when taking mean
write_tsv(collapsed, file.path(dataWithPath,"threeLetterTaskAfterExclusionsCollapsedSs.tsv"))
ggplot(ti, aes(x=twoOrMore)) + geom_histogram()
print(swappers)
swappers <- ti %>% filter(twoOrMore>.2)
print(swappers)
ggplot(ti, aes(x=twoOrMore)) + geom_histogram()
devtools::install_github('alexholcombe/mixRSVP',build_vignettes=TRUE)
package_version('mixRSVP')
packageVersion('mixRSVP')
getwd()
library(eyelinkReader)
EDF_example <- "../dataEyetracking/results for p14 10.15am aug10.EDF"
gaze <- read_edf(EDF_example)
plot(gaze, trial = 1, show_fixations = TRUE, show_saccades = TRUE)
#To do this, I could either set up an area of interest maybe, or manually
# import samples with selected attributes
gazeXY <- read_edf(EDF_example,
import_samples = TRUE,
sample_attributes = c('time', 'gx', 'gy'))
?eyelinkReader
browseVignettes('eyelinkReader')
eyelinkRecording
eyelinkReader
library(eyelinkReader)
eyelinkReader
class(gazeXY)
gazeXY$samples
head(gazeXY)
head(gazeXY)
head(gazeXY$samples)
#Left eye was recorded, so the samples are in gxL and gyL
head(gazeXY$samples$gxL)
eyelinkReader
?eyelinkReader
read_preamble(EDF_example)
print.eyelinkRecording(EDF_example)
#Work out how to go through all values and detect deviations
mean(gazeXY$samples$gxL)
gazeXY$samples$gxL
?mean
#Work out how to go through all values and detect deviations
mean(gazeXY$samples$gxL, na.rm=T)
install.packages('tidyverse')
#Start using tidyverse to calculate things
library(dplyr)
gazeXY %>% summarise(na_count = sum(is.na(gXL)))
gazeXY$samples %>% summarise(na_count = sum(is.na(gXL)))
gazeXY$samples %>% summarise(na_count = sum(is.na(gxl)))
gazeXY$samples
head( gazeXY$samples )
gazeXY$samples %>% summarise(na_count = sum(is.na(gxL)))
nrows(gazeXY$samples)
nrow(gazeXY$samples)
numNAs / nrow(gazeXY$samples)
numNAs <- gazeXY$samples %>% summarise(na_count = sum(is.na(gxL)))
numNAs / nrow(gazeXY$samples)
gazeXY$samples
#Work out how to go through all values and detect deviations
mean(gazeXY$samples$gxL, na.rm=T)
mean(gazeXY$samples$gyL, na.rm=T)
meanX <- mean(gazeXY$samples$gxL, na.rm=T)
meanY <- mean(gazeXY$samples$gyL, na.rm=T)
cat('mean coordinates are: (', meanX, meanY, ')')
scrnCenter = scrnWidthHeight / 2
#Tess' Psychopy logfile says screen is 1470 x 956
scrnWidthHeight = [1470,956]
scrnCenter = scrnWidthHeight / 2
#Tess' Psychopy logfile says screen is 1470 x 956
scrnWidthHeight = (1470,956)
#Tess' Psychopy logfile says screen is 1470 x 956
scrnWidthHeight = [1470 956]
scrnCenter = scrnWidthHeight / 2
#Tess' Psychopy logfile says screen is 1470 x 956
scrnWidthHeight = c(1470, 956)
scrnCenter = scrnWidthHeight / 2
cat('scrnCenter = ', scrnCenter)
nrow(gazeXY$samples)
head(gazeXY$samples)
unique( gazeXY$amples$trial )
unique( gazeXY$samples$trial )
unique( gazeXY$samples$trial )
len( unique( gazeXY$samples$trial ) )
length( unique( gazeXY$samples$trial ) )
numTrials <- length( unique( gazeXY$samples$trial ) )
cat('number of trials =', numTrials)
exclusionDeg = 1.0 #if participant's eye is ever more than exclusionDeg away from fixation, Exclusion=1
widthPix = scrnWidthHeight[0]
heightPix = scrnWidthHeight[1]
monitorWidth = 39 #cm
viewdist = 57 #cm
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
pixelsPerDegree = widthPix / widthScreenDeg
exclusionPixels = exclusionDeg * pixelsPerDegree
centralZoneWidthPix = exclusionPixels*2
centralZoneHeightPix = exclusionPixels*2
leftLimitPixel = widthPix/2 - centralZoneWidthPix/2
rightLimitPixel = widthPix/2 + centralZoneWidthPix/2
bottomLimitPixel = heightPix/2 + centralZoneHeightPix/2
topLimitPixel = heightPix/2 - centralZoneHeightPix/2
leftLimitPixel
widthScreenDeg
pixelsPerDegree
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
widthScreenDeg
widthPix
widthPix = scrnWidthHeight[0]
heightPix = scrnWidthHeight[1]
monitorWidth = 39 #cm
viewdist = 57 #cm
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
pixelsPerDegree = widthPix / widthScreenDeg
exclusionPixels = exclusionDeg * pixelsPerDegree
centralZoneWidthPix = exclusionPixels*2
centralZoneHeightPix = exclusionPixels*2
leftLimitPixel = widthPix/2 - centralZoneWidthPix/2
rightLimitPixel = widthPix/2 + centralZoneWidthPix/2
leftLimitPixel
pixelsPerDegree
widthScreenDeg
widthPix
scrnWidthHeight = c(1470, 956)
scrnCenter = scrnWidthHeight / 2
cat('scrnCenter = ', scrnCenter)
#In past work, tended to use exclusion zone of 1 degree
exclusionDeg = 1.0 #if participant's eye is ever more than exclusionDeg away from fixation, Exclusion=1
widthPix = scrnWidthHeight[0]
heightPix = scrnWidthHeight[1]
monitorWidth = 39 #cm
viewdist = 57 #cm
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
pixelsPerDegree = widthPix / widthScreenDeg
exclusionPixels = exclusionDeg * pixelsPerDegree
centralZoneWidthPix = exclusionPixels*2
centralZoneHeightPix = exclusionPixels*2
leftLimitPixel = widthPix/2 - centralZoneWidthPix/2
rightLimitPixel = widthPix/2 + centralZoneWidthPix/2
bottomLimitPixel = heightPix/2 + centralZoneHeightPix/2
topLimitPixel = heightPix/2 - centralZoneHeightPix/2
leftLimitPixel
widthPix
scrnWidthHeight[0]
scrnWidthHeight
scrnWidthHeight[1]
scrnWidthHeight = c(1470, 956)
scrnCenter = scrnWidthHeight / 2
cat('scrnCenter = ', scrnCenter)
#In past work, tended to use exclusion zone of 1 degree
exclusionDeg = 1.0 #if participant's eye is ever more than exclusionDeg away from fixation, Exclusion=1
widthPix = scrnWidthHeight[1]
heightPix = scrnWidthHeight[2]
monitorWidth = 39 #cm
viewdist = 57 #cm
widthScreenDeg =  2*(atan((monitorWidth/2)/viewdist) /pi*180)
pixelsPerDegree = widthPix / widthScreenDeg
exclusionPixels = exclusionDeg * pixelsPerDegree
centralZoneWidthPix = exclusionPixels*2
centralZoneHeightPix = exclusionPixels*2
leftLimitPixel = widthPix/2 - centralZoneWidthPix/2
rightLimitPixel = widthPix/2 + centralZoneWidthPix/2
bottomLimitPixel = heightPix/2 + centralZoneHeightPix/2
topLimitPixel = heightPix/2 - centralZoneHeightPix/2
leftLimitPixel
rightLimitPixel
EDF_example <- "../dataEyetracking/results for p15 11.30am aug10.EDF"
gaze <- read_edf(EDF_example)
plot(gaze, trial = 1, show_fixations = TRUE, show_saccades = TRUE)
